{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fad1a77-44a8-4299-a5d8-122a4faf8b5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "def ensure(pkgs): subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--quiet\", *pkgs])\n",
    "ensure([\"albumentations\", \"segmentation_models_pytorch\", \"tqdm\", \"torchmetrics>=1.3.0\", \"jupyter\", \"ipywidgets\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6723b0c1-15a3-4532-84ef-a14610d3fe33",
   "metadata": {},
   "source": [
    "## Датасетик качаем"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a333b0-ba1a-4707-9ac0-9374b27d1ded",
   "metadata": {
    "tags": []
   },
   "source": [
    "| Критерий                             | Обоснование                                                                                                                                                                                                                        |\n",
    "| ------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Реальная практическая значимость** | Ранняя и точная сегментация границ кожных поражений (меланома, невусы, базальноклеточный рак) критична для поддержки решений дерматологов и систем компьютерного зрения, снижает риск пропустить злокачественные изменения.        |\n",
    "| **Разнообразие и баланс классов**    | ≈2594 изображений с масками «поражение/фон» разного цвета кожи, типа и локализации участков; одноклассовая (бинарная) задача, но большая вариативность размеров, формы, текстуры и освещения.                                      |\n",
    "| **Размер и доступность**             | Общий объём ≈600 МБ (JPEG+PNG), легко обрабатывается на студенческом ПК или в Colab; подходит для глубокого обучения без распределённых систем.                                                                                    |\n",
    "| **Качество аннотаций**               | Бинарные маски созданы и верифицированы экспертами-дерматологами из ISIC Archive; чёткие границы способствуют обучению моделей с высокой точностью сегментации.                                                                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baca624f-6a3e-4fdd-b57d-8bf9c9affab5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install kaggle --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f6463f6-807e-4224-9f05-371d2f3ae6fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download -d tschandl/isic2018-challenge-task1-data-segmentation --unzip -p ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55eab240-9706-451f-b5e0-91b1a7f64191",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: unzip: not found\n"
     ]
    }
   ],
   "source": [
    "!unzip archive.zip ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30cec08e-87db-4af3-a907-972759bdd3d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root = Path(\"/home/data\")\n",
    "\n",
    "img_dir  = root / \"ISIC2018_Task1-2_Training_Input\"\n",
    "mask_dir = root / \"ISIC2018_Task1_Training_GroundTruth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e50db8b-0daf-4a6a-8a54-ad4cbc1e10a1",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5711e26b-bce8-4662-a7fb-a6b037be52c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import platform\n",
    "import random\n",
    "import warnings\n",
    "import functools\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchmetrics.classification import BinaryF1Score as Dice\n",
    "from torchmetrics.classification import BinaryJaccardIndex as JaccardIndex\n",
    "from torchmetrics.classification import BinaryAccuracy as Accuracy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "IMG_SIZE = 320"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25457c44-baa7-4997-ab6c-7f8552fbedf1",
   "metadata": {},
   "source": [
    "## Полезные штучки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c037f3e-748c-4968-908f-e8eae5dcc60f",
   "metadata": {},
   "source": [
    "### Датасет + аугментации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85caea5d-3cfb-46fe-a8a1-3e745e181230",
   "metadata": {
    "tags": []
   },
   "source": [
    "| Этап                             | Операции                                                                                                                                                                                                                                                                                     |\n",
    "| -------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Аугментации для обучения**     | - `HorizontalFlip` + `VerticalFlip` (случайные отражения)<br>- `ElasticTransform` (α=120, σ=15, p=0.3)<br>- `ColorJitter` (±20 % яркости/контраста/насыщенности, ±10 % оттенка)<br>- `Resize` → `IMG_SIZE×IMG_SIZE`<br>- `Normalize` + `ToTensorV2` (пиксели \\[0,1], транспонирование маски) |\n",
    "| **Преобразования для валидации** | - `Resize` → `IMG_SIZE×IMG_SIZE`<br>- `Normalize` + `ToTensorV2` (без случайных операций)                                                                                                                                                                                                    |\n",
    "| **Разделение 80 / 20**           | - 80 % (`train_ds`) с `RAND_AUG`, `shuffle=True`<br>- 20 % (`val_ds`) с `BASE_AUG`, `shuffle=False`<br>- `batch_size` задаётся в `make_loaders()`                                                                                                                                            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad6be4b8-739c-419c-8e2e-3dd851596ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@functools.lru_cache(maxsize=None)\n",
    "def read_rgb(path):\n",
    "    return cv2.imread(path)[:, :, ::-1].copy()\n",
    "\n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_dir,\n",
    "        mask_dir,\n",
    "        augment,\n",
    "    ):\n",
    "        self.imgs = sorted(\n",
    "            glob.glob(str(img_dir / \"*.jpg\"))\n",
    "        )\n",
    "        self.masks = sorted(\n",
    "            glob.glob(str(mask_dir / \"*.png\"))\n",
    "        )\n",
    "        self.aug = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = read_rgb(self.imgs[index])\n",
    "        mask = (\n",
    "            cv2.imread(self.masks[index], 0) > 0\n",
    "        ).astype(\"float32\")[..., None]\n",
    "        out = self.aug(image=img, mask=mask)\n",
    "        img, mask = out[\"image\"], out[\"mask\"]\n",
    "        #img = torch.from_numpy(img.transpose(2, 0, 1) / 255.0).float()\n",
    "        #mask = torch.from_numpy(mask.transpose(2, 0, 1)).float()\n",
    "        return img, mask\n",
    "\n",
    "BASE_AUG = A.Compose([\n",
    "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "    A.Normalize(mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0)),\n",
    "    ToTensorV2(transpose_mask=True),\n",
    "])\n",
    "\n",
    "RAND_AUG = A.Compose([\n",
    "    A.HorizontalFlip(), A.VerticalFlip(),\n",
    "    A.ElasticTransform(alpha=120, sigma=15, p=0.3),\n",
    "    A.ColorJitter(0.2,0.2,0.2,0.1),\n",
    "    A.Normalize(mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0)),\n",
    "    ToTensorV2(transpose_mask=True),\n",
    "])\n",
    "\n",
    "full_ds = ISICDataset(\n",
    "    img_dir,\n",
    "    mask_dir,\n",
    "    BASE_AUG,\n",
    ")\n",
    "train_len = int(0.8 * len(full_ds))\n",
    "val_len = len(full_ds) - train_len\n",
    "train_ds, val_ds = random_split(\n",
    "    full_ds,\n",
    "    [train_len, val_len],\n",
    ")\n",
    "\n",
    "\n",
    "def make_loaders(\n",
    "    batch: int,\n",
    "    augment: bool,\n",
    "):\n",
    "    train_ds.dataset.aug = (\n",
    "        RAND_AUG if augment else BASE_AUG\n",
    "    )\n",
    "    val_ds.dataset.aug = BASE_AUG\n",
    "    return (\n",
    "        DataLoader(\n",
    "            train_ds,\n",
    "            batch_size=batch,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True,\n",
    "        ),\n",
    "        DataLoader(\n",
    "            val_ds,\n",
    "            batch_size=batch,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58512662-4b7a-4bfb-b36b-74f73d2e38a8",
   "metadata": {},
   "source": [
    "### Метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f98520-6794-4fcd-a8d5-019a90ad01b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "- **Dice (коэффициент Диcа)**  \n",
    "  - Оценивает степень перекрытия предсказанной области \\(P\\) и эталонной маски \\(G\\), с дополнительным весом на пересечение.  \n",
    "  - Хорошо работает при сильном дисбалансе классов (малые поражения).  \n",
    "\n",
    "- **IoU (Jaccard Index)**   \n",
    "  - Измеряет отношение пересечения к объединению областей; более строгая метрика, чем Dice (каждый невключённый пиксель сильнее штрафуется).  \n",
    "\n",
    "- **Accuracy (точность)**  \n",
    "  - Доля правильно классифицированных пикселей (True Positives + True Negatives от общего числа).  \n",
    "  - Может давать завышенные результаты, если фон (Negative класс) сильно преобладает.  \n",
    "\n",
    "- **Практические детали**  \n",
    "  - По умолчанию все метрики порогируют вероятности на 0.5.  \n",
    "  - В начале каждой оценки вызывается `reset_metrics()` для обнуления накопленных значений.  \n",
    "  - После прохода по всем батчам `compute()` возвращает усреднённый результат за весь загрузчик.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca07b4ef-8c00-4a25-980e-a4ff8db0e4d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dice_metric = Dice().to(DEVICE)\n",
    "iou_metric  = JaccardIndex().to(DEVICE)\n",
    "acc_metric  = Accuracy().to(DEVICE)\n",
    "\n",
    "def reset_metrics():\n",
    "    dice_metric.reset()\n",
    "    iou_metric.reset()\n",
    "    acc_metric.reset()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    reset_metrics()\n",
    "    model.eval()\n",
    "\n",
    "    for images, masks in loader:\n",
    "        images = images.to(DEVICE)\n",
    "        masks = masks.to(DEVICE)\n",
    "\n",
    "        predictions = torch.sigmoid(model(images))\n",
    "        dice_metric.update(predictions, masks)\n",
    "        iou_metric.update(predictions, masks)\n",
    "        acc_metric.update(predictions, masks)\n",
    "\n",
    "    dice_score = float(dice_metric.compute())\n",
    "    iou_score = float(iou_metric.compute())\n",
    "    accuracy_score = float(acc_metric.compute())\n",
    "\n",
    "    return dice_score, iou_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f415d0c-a39a-4a7b-a01c-ce106c3aea0c",
   "metadata": {},
   "source": [
    "### Функции обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dba8580-cfcb-4b15-80c6-93fa8c09a4cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    cfg: dict,\n",
    ") -> tuple[nn.Module, tuple[float, float, float]]:\n",
    "    train_dl, val_dl = make_loaders(\n",
    "        batch   = cfg[\"batch\"],\n",
    "        augment = cfg[\"augment\"],\n",
    "    )\n",
    "\n",
    "    model = model.to(DEVICE)\n",
    "    # model = torch.compile(model)\n",
    "\n",
    "    scaler     = GradScaler()\n",
    "    optimizer  = optim.AdamW(model.parameters(),\n",
    "                             lr=cfg[\"lr\"], weight_decay=1e-4)\n",
    "    sched      = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, max_lr=cfg[\"lr\"],\n",
    "        epochs=cfg[\"epochs\"],\n",
    "        steps_per_epoch=len(train_dl)//cfg[\"acc_steps\"],\n",
    "        pct_start=0.1, div_factor=25, final_div_factor=100,\n",
    "    )\n",
    "\n",
    "    loss_fn            = cfg[\"loss\"]\n",
    "    accumulation_steps = cfg[\"acc_steps\"]\n",
    "\n",
    "    for epoch in range(1, cfg[\"epochs\"] + 1):\n",
    "        model.train()\n",
    "        grad_step   = 0\n",
    "        running_loss= 0.0\n",
    "        start_time  = time.time()\n",
    "\n",
    "        for images, masks in tqdm(\n",
    "            train_dl,\n",
    "            desc=f\"Epoch {epoch}/{cfg['epochs']}\",\n",
    "            leave=False,\n",
    "        ):\n",
    "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "\n",
    "            if grad_step == 0:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            with autocast():\n",
    "                preds = model(images)\n",
    "                loss  = loss_fn(preds, masks) / accumulation_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            running_loss += loss.item() * accumulation_steps\n",
    "            grad_step += 1\n",
    "\n",
    "            if grad_step == accumulation_steps:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                sched.step()\n",
    "                grad_step = 0\n",
    "\n",
    "        dice, iou, acc = evaluate(model, val_dl)\n",
    "        epoch_time     = time.time() - start_time\n",
    "        avg_loss       = running_loss / len(train_dl)\n",
    "\n",
    "        print(\n",
    "            f\"Ep {epoch:02d}/{cfg['epochs']} \"\n",
    "            f\"| loss {avg_loss:.4f} \"\n",
    "            f\"| Dice {dice:.4f} \"\n",
    "            f\"| IoU {iou:.4f} \"\n",
    "            f\"| Acc {acc:.4f} \"\n",
    "            f\"| {epoch_time:.1f}s/ep\"\n",
    "        )\n",
    "\n",
    "    return model, (dice, iou, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1014e6c-847e-48a8-a94c-e133389fec46",
   "metadata": {},
   "source": [
    "### Лосс"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df228829-2ac5-4cfc-859d-22e8de34075c",
   "metadata": {
    "tags": []
   },
   "source": [
    "- **BCEWithLogitsLoss**  \n",
    "  - Реализует бинарную кросс-энтропию с учётом логитов (внутри применяется `sigmoid`).  \n",
    "  - Штрафует разницу по-пиксельно, особенно чувствителен к редким ошибкам при большом фоне.  \n",
    "\n",
    "- **Combo Loss**  \n",
    "  - Балансирует пиксельную точность (BCE) и глобальное перекрытие (Dice).  \n",
    "  - Сглаживание «+1» в Dice предотвращает деление на ноль, когда маска пустая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf400754-5de3-42a4-b1a8-42c57c00a3d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def combo_loss(\n",
    "    predictions: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    dice_numerator = (\n",
    "        2 * (predictions.sigmoid() * targets).sum() + 1\n",
    "    )\n",
    "    dice_denominator = (\n",
    "        predictions.sigmoid().sum() + targets.sum() + 1\n",
    "    )\n",
    "    dice_score = dice_numerator / dice_denominator\n",
    "\n",
    "    loss = (\n",
    "        0.5 * bce_loss(predictions, targets)\n",
    "        + 0.5 * (1 - dice_score)\n",
    "    )\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e295a31-f972-4099-8e3c-e000bfe8befd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Свои модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e60a4a8-c901-4748-bf9a-b727da4abbfd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Просто моделька"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fadc89c-27d8-474b-83aa-37486b3ba0df",
   "metadata": {},
   "source": [
    "| Блок        | Что делает                                                                                                                                                            |\n",
    "| :---------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **e1**      | Два подряд 3 × 3 Conv (in=3 → out=f) + ReLU; сохраняет пространственный размер, извлекает начальные признаки из RGB-изображения.                                      |\n",
    "| **e2**      | MaxPool2d 2 × 2 (H,W → H/2,W/2) + 3 × 3 Conv (in=f → out=2f) + ReLU; уменьшает разрешение вдвое, удваивает число каналов для более глубоких признаков.                |\n",
    "| **e3**      | MaxPool2d 2 × 2 + 3 × 3 Conv (in=2f → out=4f) + ReLU; повторяет снижение разрешения и расширение каналов для вычленения ещё более абстрактных признаков.              |\n",
    "| **mid**     | MaxPool2d 2 × 2 + 3 × 3 Conv (in=4f → out=8f) + ReLU; «бутылочное горлышко» U-Net — максимальная глубина, здесь сосредоточены самые глобальные признаки объекта.      |\n",
    "| **u2 + d2** | `ConvTranspose2d(in=8f→4f, k=2, s=2)` ↑2 → конкатенация с e3 (4f+4f=8f) → 3 × 3 Conv (in=8f → out=4f) + ReLU; первый этап декодера, восстанавливает разрешение вдвое. |\n",
    "| **u1 + d1** | `ConvTranspose2d(in=4f→2f, k=2, s=2)` ↑2 → конкатенация с e2 (2f+2f=4f) → 3 × 3 Conv (in=4f → out=2f) + ReLU; второй уровень декодера.                                |\n",
    "| **u0 + d0** | `ConvTranspose2d(in=2f→f, k=2, s=2)` ↑2 → конкатенация с e1 (f+f=2f) → 3 × 3 Conv (in=2f → out=f) + ReLU; финальный уровень декодера, возвращает исходное разрешение. |\n",
    "| **head**    | 1 × 1 Conv (in=f → out=1); проекция f-канального тензора в одноканальную логит-маску для бинарной сегментации.                                                        |\n",
    "- Узел «конкатенации» обеспечивает передачу локальных деталей из энкодера в декодер.\n",
    "- ConvTranspose2d разворачивает пространственные размеры (upsampling), вместо интерполяции.\n",
    "- ReLU после каждого свёрточного слоя позволяет сети моделировать нелинейные отношения в данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a75707d-07ec-42ad-8aa0-6c067d25d24f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TinyUNet(nn.Module):\n",
    "    def __init__(self, f: int = 32):\n",
    "        super().__init__()\n",
    "        self.e1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,\n",
    "                out_channels=f,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=f,\n",
    "                out_channels=f,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.e2 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=f,\n",
    "                out_channels=2 * f,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.e3 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=2 * f,\n",
    "                out_channels=4 * f,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.mid = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=4 * f,\n",
    "                out_channels=8 * f,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.u2 = nn.ConvTranspose2d(\n",
    "            in_channels=8 * f,\n",
    "            out_channels=4 * f,\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "        )\n",
    "        self.d2 = nn.Conv2d(\n",
    "            in_channels=8 * f,\n",
    "            out_channels=4 * f,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "        )\n",
    "\n",
    "        self.u1 = nn.ConvTranspose2d(\n",
    "            in_channels=4 * f,\n",
    "            out_channels=2 * f,\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "        )\n",
    "        self.d1 = nn.Conv2d(\n",
    "            in_channels=4 * f,\n",
    "            out_channels=2 * f,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "        )\n",
    "\n",
    "        self.u0 = nn.ConvTranspose2d(\n",
    "            in_channels=2 * f,\n",
    "            out_channels=f,\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "        )\n",
    "        self.d0 = nn.Conv2d(\n",
    "            in_channels=2 * f,\n",
    "            out_channels=f,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "        )\n",
    "\n",
    "        self.head = nn.Conv2d(\n",
    "            in_channels=f,\n",
    "            out_channels=1,\n",
    "            kernel_size=1,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        e1 = self.e1(x)\n",
    "        e2 = self.e2(e1)\n",
    "        e3 = self.e3(e2)\n",
    "        m = self.mid(e3)\n",
    "\n",
    "        d2 = self.u2(m)\n",
    "        d2 = torch.cat([d2, e3], dim=1)\n",
    "        d2 = torch.relu(self.d2(d2))\n",
    "\n",
    "        d1 = self.u1(d2)\n",
    "        d1 = torch.cat([d1, e2], dim=1)\n",
    "        d1 = torch.relu(self.d1(d1))\n",
    "\n",
    "        d0 = self.u0(d1)\n",
    "        d0 = torch.cat([d0, e1], dim=1)\n",
    "        d0 = torch.relu(self.d0(d0))\n",
    "\n",
    "        return self.head(d0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1996d96a-0d14-4ebf-bb4c-65b3dab600aa",
   "metadata": {},
   "source": [
    "### Улучшенная типо"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac8693-1eef-4a8e-bfbd-67423aec5cd0",
   "metadata": {},
   "source": [
    "| Блок                               | Что делает                                                                                                                                            |\n",
    "| :--------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **patch\\_conv**                    | 2D-свёртка патчами (kernel=patch\\_size, stride=patch\\_size): из RGB-изображения формирует тензор размером (B, dim, H/patch, W/patch).                 |\n",
    "| **cls\\_token + pos\\_embed**        | Добавляет learnable токен класса и позиционные эмбеддинги к последовательности патч-векторов (размер N\\_patches+1).                                   |\n",
    "| **encoder**                        | TransformerEncoder из `depth` слоёв с `nhead` головами и FFN размером `dim*mlp`; обрабатывает токены, моделируя глобальные взаимосвязи между патчами. |\n",
    "| **reshape → feature map**          | Убирает первый (cls) токен, транспонирует и ресайзит последовательность обратно в карту признаков (B, dim, H/patch, W/patch).                         |\n",
    "| **up (ConvTranspose2d + Conv1×1)** | Расширяет карту признаков вдвое (dim→dim/2), применяет ReLU и 1×1-свёртку для получения одноканального предсказания низкого разрешения.               |\n",
    "| **interpolate**                    | Билинейно масштабирует предсказание с (H/patch, W/patch) обратно до оригинального (H, W) без артефактов.                                              |\n",
    "\n",
    "- Патчи позволяют Transformer-модулям работать на более низком разрешении, экономя память.\n",
    "- Positional embedding даёт информацию о расположении патча в картинке.\n",
    "- Использование ConvTranspose2d вместо простой интерполяции добавляет обучаемые параметры при восстановлении пространственных деталей.\n",
    "- Билинейная интерполяция на конце гарантирует плавное увеличение до исходного размера без пикселизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c66edae6-0ade-4403-944b-d076e96e1a88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PatchViTSeg(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        img: int = IMG_SIZE,\n",
    "        patch: int = 16,\n",
    "        dim: int = 256,\n",
    "        depth: int = 4,\n",
    "        heads: int = 4,\n",
    "        mlp: int = 2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch\n",
    "\n",
    "        self.patch_conv = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=dim,\n",
    "            kernel_size=self.patch_size,\n",
    "            stride=self.patch_size,\n",
    "        )\n",
    "        num_patches = (img // self.patch_size) ** 2\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, dim))\n",
    "        self.pos_embed = nn.Parameter(\n",
    "            torch.randn(1, num_patches + 1, dim) * 0.02\n",
    "        )\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=dim,\n",
    "            nhead=heads,\n",
    "            dim_feedforward=dim * mlp,\n",
    "            batch_first=True,\n",
    "            norm_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=depth,\n",
    "        )\n",
    "\n",
    "        self.up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=dim,\n",
    "                out_channels=dim // 2,\n",
    "                kernel_size=2,\n",
    "                stride=2,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=dim // 2,\n",
    "                out_channels=1,\n",
    "                kernel_size=1,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        patches = self.patch_conv(x)\n",
    "        patches = patches.flatten(2).transpose(1, 2)\n",
    "\n",
    "        tokens = torch.cat(\n",
    "            [\n",
    "                self.cls_token.expand(batch_size, -1, -1),\n",
    "                patches,\n",
    "            ],\n",
    "            dim=1,\n",
    "        ) + self.pos_embed\n",
    "\n",
    "        encoded = self.encoder(tokens)\n",
    "        encoded = encoded[:, 1:]\n",
    "        encoded = encoded.transpose(1, 2).reshape(\n",
    "            batch_size,\n",
    "            -1,\n",
    "            IMG_SIZE // self.patch_size,\n",
    "            IMG_SIZE // self.patch_size,\n",
    "        )\n",
    "\n",
    "        preds_small = self.up(encoded)\n",
    "\n",
    "        preds_full = F.interpolate(\n",
    "            preds_small,\n",
    "            size=(IMG_SIZE, IMG_SIZE),\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        )\n",
    "        return preds_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3133c9fb-0e40-4590-b1a7-da0dc8848d3d",
   "metadata": {},
   "source": [
    "## Конфиги"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e268b6fb-fb21-423b-8cf3-43724eb479ea",
   "metadata": {},
   "source": [
    "| Модель            | Бэкенд    | Аугментации    | Лосс          | batch | epochs | lr      | acc\\_steps |\n",
    "| ----------------- | --------- | -------------- | ------------- | ----- | ------ | ------- | ---------- |\n",
    "| **unet\\_base**    | ResNet-34 | Нет            | BCEWithLogits | 20    | 3      | 4.2 e-3 | 1          |\n",
    "| **deeplab\\_base** | MiT-B2    | Нет            | BCEWithLogits | 9     | 3      | 4.2 e-3 | 1          |\n",
    "| **unet\\_plus**    | ResNet-34 | Да (RAND\\_AUG) | ComboLoss     | 14    | 4      | 1.4 e-3 | 1          |\n",
    "| **deeplab\\_plus** | MiT-B2    | Да (RAND\\_AUG) | ComboLoss     | 7     | 4      | 1.4 e-3 | 1          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a91fd410-9146-4f2c-ac2f-9d552b9824bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    \"unet_base\": dict(\n",
    "        batch=20, epochs=3,  lr=4.2e-3,\n",
    "        augment=False, loss=bce_loss, acc_steps=1,\n",
    "        create=lambda: smp.Unet(\"resnet34\", encoder_weights=\"imagenet\",\n",
    "                                classes=1, activation=None)\n",
    "    ),\n",
    "\n",
    "    \"deeplab_base\": dict(\n",
    "        batch=9,  epochs=3,  lr=4.2e-3,\n",
    "        augment=False, loss=bce_loss, acc_steps=1,\n",
    "        create=lambda: smp.DeepLabV3Plus(\"mit_b2\", encoder_weights=\"imagenet\",\n",
    "                                         classes=1, activation=None)\n",
    "    ),\n",
    "\n",
    "    \"unet_plus\": dict(\n",
    "        batch=14, epochs=4,  lr=1.4e-3,\n",
    "        augment=True,  loss=combo_loss, acc_steps=1,\n",
    "        create=lambda: smp.Unet(\"resnet34\", encoder_weights=\"imagenet\",\n",
    "                                classes=1, activation=None)\n",
    "    ),\n",
    "\n",
    "    \"deeplab_plus\": dict(\n",
    "        batch=7,  epochs=4,  lr=1.4e-3,\n",
    "        augment=True,  loss=combo_loss, acc_steps=1,\n",
    "        create=lambda: smp.DeepLabV3Plus(\"mit_b2\", encoder_weights=\"imagenet\",\n",
    "                                         classes=1, activation=None)\n",
    "    ),\n",
    "\n",
    "    \"tiny_unet\": dict(\n",
    "        batch=32, epochs=5,  lr=1.4e-3,\n",
    "        augment=True,  loss=combo_loss, acc_steps=1, create=TinyUNet\n",
    "    ),\n",
    "\n",
    "    \"vit_seg\": dict(\n",
    "        batch=4,  epochs=5,  lr=7e-4,\n",
    "        augment=True,  loss=combo_loss, acc_steps=2, create=PatchViTSeg\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da384cac-7dbf-4df5-a1e0-cf7cd570ac69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== unet_base ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c0a253c32948a1bc3f627d52134a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 01/3 | loss 0.2733 | Dice 0.5910 | IoU 0.4194 | Acc 0.7275 | 342.8s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc96181ad8404138b693af0a32a6c5b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 02/3 | loss 0.1871 | Dice 0.8016 | IoU 0.6688 | Acc 0.9227 | 345.8s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1097ddfd2b24c899c4cdd560183b7e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 03/3 | loss 0.1466 | Dice 0.8607 | IoU 0.7555 | Acc 0.9410 | 342.3s/ep\n",
      "\n",
      "=== deeplab_base ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ccd97fcb9b440bbbc10ff03c4e7c367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/3:   0%|          | 0/231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 01/3 | loss 0.2875 | Dice 0.7907 | IoU 0.6539 | Acc 0.9085 | 359.0s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98ef3a209684103979a8f1db1f60b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/3:   0%|          | 0/231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 02/3 | loss 0.2338 | Dice 0.7628 | IoU 0.6166 | Acc 0.9106 | 344.0s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d142c03bcaf5439785139a0b5d47350a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/3:   0%|          | 0/231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 03/3 | loss 0.2126 | Dice 0.8060 | IoU 0.6750 | Acc 0.9229 | 379.9s/ep\n",
      "\n",
      "=== unet_plus ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3adc4614551e4ce9b8ef441929380e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/4:   0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 01/4 | loss 0.3107 | Dice 0.7631 | IoU 0.6170 | Acc 0.8901 | 365.0s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b681bc0ed1a42d3bf6a36bd6981b207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/4:   0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f12610abeb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f12610abeb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 02/4 | loss 0.1861 | Dice 0.8135 | IoU 0.6856 | Acc 0.9266 | 352.5s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5185ee5d09a744efa5cc933cfbd1a62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/4:   0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f12610abeb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f12610abeb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f12610abeb0>  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "Exception ignored in:   File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f12610abeb0>BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 03/4 | loss 0.1490 | Dice 0.8747 | IoU 0.7774 | Acc 0.9477 | 353.9s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46012d120c1f4627b498d09a95943d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/4:   0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 04/4 | loss 0.1219 | Dice 0.8879 | IoU 0.7983 | Acc 0.9515 | 351.2s/ep\n",
      "\n",
      "=== deeplab_plus ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f12610abeb0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd78b0edf95485bb81e371e460824ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/4:   0%|          | 0/297 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 251, in _feed\n",
      "    send_bytes(obj)\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f12610abeb0>  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 205, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 416, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 373, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 01/4 | loss 0.3275 | Dice 0.5264 | IoU 0.3573 | Acc 0.6230 | 367.8s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77bce35e212a483fbbeca26394778388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/4:   0%|          | 0/297 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 02/4 | loss 0.2532 | Dice 0.7919 | IoU 0.6555 | Acc 0.9157 | 360.3s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0f0122450a493f9d433b0906e359ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/4:   0%|          | 0/297 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 03/4 | loss 0.2294 | Dice 0.7923 | IoU 0.6560 | Acc 0.9204 | 360.4s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264a5f0aeed647dda0b8c7b4fc63cc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/4:   0%|          | 0/297 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 04/4 | loss 0.2072 | Dice 0.8339 | IoU 0.7151 | Acc 0.9321 | 363.3s/ep\n",
      "\n",
      "=== tiny_unet ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1adf7093085c432e9a3363414ca0593f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 01/5 | loss 0.5529 | Dice 0.5853 | IoU 0.4137 | Acc 0.8464 | 362.8s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8167361b5bac48e3ab468da15c8a7ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 02/5 | loss 0.4242 | Dice 0.6079 | IoU 0.4367 | Acc 0.8604 | 373.3s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86fb2162ac334b8a8f4b78ff8819c1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, cfg in CFG.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "\n",
    "    model = cfg[\"create\"]()\n",
    "\n",
    "    _, metrics = train_model(\n",
    "        model=model,\n",
    "        cfg=cfg,\n",
    "    )\n",
    "\n",
    "    results.append(\n",
    "        [\n",
    "            name,\n",
    "            *metrics,\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfe2f7ab-4e62-4cfc-86ce-fb5455430b29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    \"tiny_unet\": dict(\n",
    "        batch=32, epochs=5,  lr=1.4e-3,\n",
    "        augment=True,  loss=combo_loss, acc_steps=1, create=TinyUNet\n",
    "    ),\n",
    "\n",
    "    \"vit_seg\": dict(\n",
    "        batch=4,  epochs=5,  lr=7e-4,\n",
    "        augment=True,  loss=combo_loss, acc_steps=2, create=PatchViTSeg\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b80d94e-85e9-4015-b623-40715657637f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== tiny_unet ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2647224ce784b76b7fc4e133903b51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 01/5 | loss 0.5691 | Dice 0.5437 | IoU 0.3733 | Acc 0.8438 | 374.4s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcad9c849ad42c1b6e54b135b7cf1fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 02/5 | loss 0.4302 | Dice 0.6101 | IoU 0.4389 | Acc 0.8611 | 357.7s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e536c961ed485cbffeec6ddc8c0b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 03/5 | loss 0.3838 | Dice 0.6681 | IoU 0.5016 | Acc 0.8753 | 356.0s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce39c3c57f541daa20c7e0f06e5cdc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 04/5 | loss 0.3399 | Dice 0.7178 | IoU 0.5598 | Acc 0.8797 | 635.2s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a8dde9afa2405e95bffb2bbfc7d0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9779cdb9a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9779cdb9a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9779cdb9a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9779cdb9a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9779cdb9a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9779cdb9a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9779cdb9a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9779cdb9a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9779cdb9a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9779cdb9a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9779cdb9a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f9779cdb9a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 05/5 | loss 0.3171 | Dice 0.7176 | IoU 0.5595 | Acc 0.8859 | 407.4s/ep\n",
      "\n",
      "=== vit_seg ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d633fe7e4a949669e346785f70386b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'patch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate\u001b[39m\u001b[38;5;124m\"\u001b[39m]()\n\u001b[0;32m----> 8\u001b[0m _, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     14\u001b[0m     [\n\u001b[1;32m     15\u001b[0m         name,\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;241m*\u001b[39mmetrics,\n\u001b[1;32m     17\u001b[0m     ]\n\u001b[1;32m     18\u001b[0m )\n",
      "Cell \u001b[0;32mIn[6], line 46\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, cfg)\u001b[0m\n\u001b[1;32m     43\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[0;32m---> 46\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     loss  \u001b[38;5;241m=\u001b[39m loss_fn(preds, masks) \u001b[38;5;241m/\u001b[39m accumulation_steps\n\u001b[1;32m     49\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 74\u001b[0m, in \u001b[0;36mPatchViTSeg.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m encoded \u001b[38;5;241m=\u001b[39m encoded[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     70\u001b[0m encoded \u001b[38;5;241m=\u001b[39m encoded\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     71\u001b[0m encoded \u001b[38;5;241m=\u001b[39m encoded\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m     72\u001b[0m     batch_size,\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m---> 74\u001b[0m     IMG_SIZE \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[43mpatch\u001b[49m,\n\u001b[1;32m     75\u001b[0m     IMG_SIZE \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m patch,\n\u001b[1;32m     76\u001b[0m )\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup(encoded)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'patch' is not defined"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, cfg in CFG.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "\n",
    "    model = cfg[\"create\"]()\n",
    "\n",
    "    _, metrics = train_model(\n",
    "        model=model,\n",
    "        cfg=cfg,\n",
    "    )\n",
    "\n",
    "    results.append(\n",
    "        [\n",
    "            name,\n",
    "            *metrics,\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d1c49de-269f-44ca-b803-76ccc40a1ebb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    \"vit_seg\": dict(\n",
    "        batch=4,  epochs=5,  lr=7e-4,\n",
    "        augment=True,  loss=combo_loss, acc_steps=2, create=PatchViTSeg\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5aa349ec-8096-41df-98d0-6c462d8d0516",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== vit_seg ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c3c0eacd30459ba01daa89d5b15bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 01/5 | loss 0.3919 | Dice 0.7910 | IoU 0.6543 | Acc 0.9110 | 393.7s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98c03be2aac431b8d2b8a4dff8366ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 02/5 | loss 0.2683 | Dice 0.7713 | IoU 0.6277 | Acc 0.9125 | 375.9s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3d5c012c46410d95a29e36df26e9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 03/5 | loss 0.2405 | Dice 0.7848 | IoU 0.6458 | Acc 0.9165 | 358.6s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb2f857e7ad483186508773a2167fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 04/5 | loss 0.2024 | Dice 0.8277 | IoU 0.7061 | Acc 0.9289 | 371.8s/ep\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a87888639a3481891f82b9fec5b5374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 05/5 | loss 0.1884 | Dice 0.8391 | IoU 0.7228 | Acc 0.9316 | 371.1s/ep\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name, cfg in CFG.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "\n",
    "    model = cfg[\"create\"]()\n",
    "\n",
    "    _, metrics = train_model(\n",
    "        model=model,\n",
    "        cfg=cfg,\n",
    "    )\n",
    "\n",
    "    results.append(\n",
    "        [\n",
    "            name,\n",
    "            *metrics,\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7970f4-9aea-4fd7-a3a3-6edbdb85380e",
   "metadata": {},
   "source": [
    "## Результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f03918-b0da-4be7-b606-86574790d8bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=[\"Model\",\"Dice\",\"IoU\",\"PixAcc\"])\n",
    "print(\"\\n===== Итоговые метрики (GPU:\", torch.cuda.get_device_name(0), \") =====\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e57ee8-5f0f-443d-ac4b-def7f521284e",
   "metadata": {},
   "source": [
    "| Модель           | Эпохи |   Loss   |  Dice   |   IoU   |   Acc   | Время (с/эп) |\n",
    "|------------------|:-----:|:--------:|:-------:|:-------:|:-------:|:------------:|\n",
    "| **unet_base**    |  3/3  |  0.1466  | 0.8607  | 0.7555  | 0.9410  |    342.3     |\n",
    "| **deeplab_base** |  3/3  |  0.2126  | 0.8060  | 0.6750  | 0.9229  |    379.9     |\n",
    "| **unet_plus**    |  4/4  |  0.1219  | 0.8879  | 0.7983  | 0.9515  |    351.2     |\n",
    "| **deeplab_plus** |  4/4  |  0.2072  | 0.8339  | 0.7151  | 0.9321  |    363.3     |\n",
    "| **tiny_unet**    |  5/5  |  0.3171  | 0.7176  | 0.5595  | 0.8859  |    407.4     |\n",
    "| **vit_seg**      |  5/5  |  0.1884  | 0.8391  | 0.7228  | 0.9316  |    371.1     |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
