{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ol2uSenIklqf"
   },
   "source": [
    "## Качаем датасетик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Критерий                             | Обоснование                                                                                                                                                  |\n",
    "| ------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **Реальная практическая значимость** | Болезни растений снижают урожайность на 20‑40 %. Быстрая диагностика по фото листьев помогает агрономам и фермерам вовремя применять меры защиты.            |\n",
    "| **Разнообразие и баланс классов**    | 38 меток (болезненные и здоровые листья 10 культур) → задача многоклассовой классификации, богатая на меж‑ и внутриклассовые вариации.                       |\n",
    "| **Размер и доступность**             | \\~54 000 RGB‑изображений 256×256 px: достаточно данных для глубоких моделей, но объём не требует распределённых систем — студенческий ПК/Colab справится.    |\n",
    "| **Качество аннотаций**               | Метки проставлены специалистами Корнеллского университета; наличие как «здоровых», так и «болезненных» классов упрощает формирование отрицательных примеров. |\n",
    "| **Возможность расширения**           | Позволяет тестировать аугментации (flip, color jitter, CutMix), transfer learning (ResNet, ViT, Swin) и кастомные CNN с вниманием к мелким пятнам.           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UmyAjeY-eWJA",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install kaggle --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XGqaCY4yf25k",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JrTdKMv4hMIf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCFcJsNUfBMX",
    "outputId": "dac2ace0-7529-46ed-dff1-d0121c839df5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/abdallahalidev/plantvillage-dataset\n",
      "License(s): CC-BY-NC-SA-4.0\n",
      "Downloading plantvillage-dataset.zip to ./data\n",
      " 95%|████████████████████████████████████▎ | 1.95G/2.04G [00:01<00:00, 1.21GB/s]\n",
      "100%|██████████████████████████████████████| 2.04G/2.04G [00:01<00:00, 1.22GB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d abdallahalidev/plantvillage-dataset --unzip -p ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fz_4871ukq-2"
   },
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nt18FMFegfWI",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.transforms import RandAugment\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "DATA_DIR = \"/home/data/plantvillage dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4Y9kDY6k44H"
   },
   "source": [
    "## Полезные штучки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лоадер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WLHLONsJiWhk",
    "outputId": "4e32175f-8e79-41d9-d001-228494648400",
    "tags": []
   },
   "outputs": [],
   "source": [
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "IMG_SIZE = 224\n",
    "\n",
    "def make_loaders(batch: int):\n",
    "    return (\n",
    "        DataLoader(\n",
    "            train_ds,\n",
    "            batch_size=batch,\n",
    "            shuffle=True,\n",
    "            num_workers=6,\n",
    "            pin_memory=True,\n",
    "        ),\n",
    "        DataLoader(\n",
    "            val_ds,\n",
    "            batch_size=batch,\n",
    "            shuffle=False,\n",
    "            num_workers=6,\n",
    "            pin_memory=True,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аугментируйся, машина"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* **Аугментации для обучения**\n",
    "  Делается случайное кадрирование, горизонтальное отражение, два произвольных преобразования RandAugment, лёгкий поворот ±10°, затем перевод в тензор и нормализация. Цель — diversировать изображения, чтобы сеть не переучивалась на фиксированные ракурсы и цвета.\n",
    "\n",
    "* **Преобразования для валидации**\n",
    "  Изображение лишь масштабируется с запасом, жёстко центрируется до нужного размера и нормализуется. Никаких случайностей, чтобы метрика была стабильной.\n",
    "\n",
    "* **Разделение 80 / 20**\n",
    "  Отсек 80 % кадров идёт на обучение, 20 % — на проверку. Валидационной части подменяют «случайные» аугментации на детерминированные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Классов: 3 | Train: 130332 | Val:   32584\n"
     ]
    }
   ],
   "source": [
    "train_tfms = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomResizedCrop(\n",
    "            IMG_SIZE,\n",
    "            scale=(0.8, 1.0),\n",
    "        ),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        RandAugment(num_ops=2, magnitude=9),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(MEAN, STD),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_tfms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(IMG_SIZE + 32),\n",
    "        transforms.CenterCrop(IMG_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(MEAN, STD),\n",
    "    ]\n",
    ")\n",
    "\n",
    "full_ds = datasets.ImageFolder(\n",
    "    root=DATA_DIR,\n",
    "    transform=train_tfms,\n",
    ")\n",
    "num_cls = len(full_ds.classes)\n",
    "\n",
    "train_len = int(0.8 * len(full_ds))\n",
    "val_len = len(full_ds) - train_len\n",
    "train_ds, val_ds = random_split(\n",
    "    full_ds,\n",
    "    [train_len, val_len],\n",
    ")\n",
    "val_ds.dataset.transform = val_tfms\n",
    "\n",
    "print(\n",
    "    f\"Классов: {num_cls} | \"\n",
    "    f\"Train: {len(train_ds)} | \"\n",
    "    f\"Val:   {len(val_ds)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TX8sAWr2lC4o"
   },
   "source": [
    "### Обучалка + метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сбор статистики** — для каждого батча накапливаются:\n",
    "   * сумма потерь (для усреднения в конце);\n",
    "   * число верных предсказаний (для точности).\n",
    "\n",
    "В отдельном проходе без градиентов собираются все предсказания и истинные метки, после чего считаются три показателя качества:\n",
    "\n",
    "| Метрика               | Что показывает                                                                                                                                                    | Почему полезна                                                                                                 |\n",
    "| --------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------- |\n",
    "| **Accuracy**          | Простая доля совпадений «угадал / всего».                                                                                                                         | Быстрый ориентир, но может вводить в заблуждение, если классы несбалансированы.                                |\n",
    "| **Weighted F1‑score** | Для каждого класса берётся F1, затем усредняется с весами, пропорциональными числу примеров класса.                                                               | Балансирует вклад частых и редких классов; важна при дисбалансе.                                               |\n",
    "| **Cohen’s κ**         | Сравнивает согласие «модель‑эксперт» с учётом того, сколько совпадений ожидалось случайно. Значения: 1 — полное совпадение, 0 — как случай, <0 — хуже случайного. | Даёт более строгую оценку, показывая, насколько модель действительно «понимает» классы, а не просто угадывает. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4tAB42_iiYil",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def epoch_step(\n",
    "    model,\n",
    "    loader,\n",
    "    criterion,\n",
    "    optimizer=None,\n",
    "    acc_steps: int = 1,\n",
    "):\n",
    "    train_phase = optimizer is not None\n",
    "\n",
    "    if train_phase:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    running_loss = 0.0\n",
    "    grad_step = 0\n",
    "\n",
    "    for x, y in tqdm(loader, leave=False):\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "\n",
    "        if train_phase and grad_step == 0:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast():\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y) / acc_steps\n",
    "\n",
    "        if train_phase:\n",
    "            scaler.scale(loss).backward()\n",
    "            grad_step += 1\n",
    "\n",
    "            if grad_step == acc_steps:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                grad_step = 0\n",
    "\n",
    "        running_loss += loss.item() * acc_steps * y.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_metrics(model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    for x, y in loader:\n",
    "        logits = model(x.to(DEVICE))\n",
    "        preds.append(logits.argmax(dim=1).cpu())\n",
    "        labels.append(y)\n",
    "\n",
    "    preds = torch.cat(preds)\n",
    "    labels = torch.cat(labels)\n",
    "\n",
    "    return (\n",
    "        accuracy_score(labels, preds),\n",
    "        f1_score(labels, preds, average=\"weighted\"),\n",
    "        cohen_kappa_score(labels, preds),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Конфиги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HP = {\n",
    "    \"res18_base\": dict(batch=256, epochs=6,  lr=1e-3, acc_steps=1, aug=False, ckpt=False),\n",
    "    \"vit_base\":   dict(batch=64,  epochs=6,  lr=3e-4, acc_steps=1, aug=False, ckpt=True),\n",
    "    \"res18_aug\":  dict(batch=192, epochs=10, lr=3e-4, acc_steps=1, aug=True,  ckpt=False),\n",
    "    \"vit_aug\":    dict(batch=48,  epochs=10, lr=3e-4, acc_steps=1, aug=True,  ckpt=True),\n",
    "    \"cnn\":        dict(batch=512, epochs=15, lr=1e-3, acc_steps=1, aug=True,  ckpt=False),\n",
    "    \"tiny_vit\":   dict(batch=256, epochs=20, lr=5e-4, acc_steps=2, aug=True,  ckpt=False),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Свои и не чужие"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Обыкновенный"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Блок                  | Что делает                                        |\n",
    "| :-------------------- | :------------------------------------------------ |\n",
    "| **Conv 3×3 → 32…256** | 4 свёртки, каналы: 32→64→128→256                  |\n",
    "| **BatchNorm + ReLU**  | Стабилизирует признаки и вводит нелинейность      |\n",
    "| **MaxPool 2×2**       | Каждый раз вдвое уменьшает H×W                    |\n",
    "| **AdaptiveAvgPool**   | Усредняет пространства → вектор 1×256             |\n",
    "| **Linear → nc**       | Преобразует 256-мерный вектор в логиты по классам |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, nc=num_cls):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=128,\n",
    "                out_channels=256,\n",
    "                kernel_size=3,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "        self.head = nn.Linear(256, nc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.flatten(1)\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Необыкновенный, но это не точно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Компонент                        | Что делает                                                                                   |\n",
    "| :------------------------------- | :------------------------------------------------------------------------------------------- |\n",
    "| **Patch Embedding**              | Разбивает изображение на патчи 16×16 и проектирует их в пространство размерности 256         |\n",
    "| **cls\\_token + Positional Emb.** | Добавляет специальный токен «\\[CLS]» и позиционные векторы для сохранения порядка патчей     |\n",
    "| **Transformer Encoder × 4**      | 4 слоя самовнимания (4 головы) + MLP (×2) + Dropout → обрабатывают последовательность патчей |\n",
    "| **LayerNorm**                    | Нормализует итоговый embedding «\\[CLS]» перед классификацией                                 |\n",
    "| **Linear Head → nc**             | Переводит 256-мерный вектор «\\[CLS]» в логиты по числу классов                               |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TinyViT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        img=IMG_SIZE,\n",
    "        patch=16,\n",
    "        dim=256,\n",
    "        depth=4,\n",
    "        heads=4,\n",
    "        mlp=2,\n",
    "        nc=num_cls,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.patch = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=dim,\n",
    "            kernel_size=patch,\n",
    "            stride=patch,\n",
    "        )\n",
    "        n_patches = (img // patch) ** 2\n",
    "        self.cls_token = nn.Parameter(\n",
    "            torch.zeros(1, 1, dim)\n",
    "        )\n",
    "        self.pos_embed = nn.Parameter(\n",
    "            torch.randn(1, n_patches + 1, dim) * 0.02\n",
    "        )\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=dim,\n",
    "            nhead=heads,\n",
    "            dim_feedforward=dim * mlp,\n",
    "            batch_first=True,\n",
    "            norm_first=True,\n",
    "            dropout=0.1,\n",
    "            activation=\"gelu\",\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=depth,\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.head = nn.Linear(dim, nc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch(x)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        cls = self.cls_token.expand(\n",
    "            x.size(0),\n",
    "            -1,\n",
    "            -1,\n",
    "        )\n",
    "        x = torch.cat((cls, x), dim=1) + self.pos_embed\n",
    "        x = self.encoder(x)\n",
    "        x = self.norm(x[:, 0])\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Великая функция глобального захвата машинами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Настройка обучения:\n",
    "- Функция потерь — CrossEntropy с label smoothing, если есть аугментации.\n",
    "- Оптимизатор — AdamW с весовым распадом.\n",
    "- Планировщик learning rate — OneCycleLR на все эпохи.\n",
    "\n",
    "| Модель      | Архитектура                | Аугментации         | Label smoothing | Чекпоинтинг | batch | epochs |    lr | acc\\_steps |\n",
    "| :---------- | :------------------------- | :------------------ | :-------------- | :---------- | ----: | -----: | ----: | ---------: |\n",
    "| res18\\_base | ResNet-18 (pre-ImageNet)   | базовые (crop+flip) | 0.0             | нет         |   256 |      6 | 1 e-3 |          1 |\n",
    "| vit\\_base   | ViT-B/16 (pre-ImageNet)    | базовые             | 0.0             | да          |    64 |      6 | 3 e-4 |          1 |\n",
    "| res18\\_aug  | ResNet-18                  | расширенные         | 0.1             | нет         |   192 |     10 | 3 e-4 |          1 |\n",
    "| vit\\_aug    | ViT-B/16                   | расширенные         | 0.1             | да          |    48 |     10 | 3 e-4 |          1 |\n",
    "| cnn         | SimpleCNN (4 Conv блока)   | расширенные         | 0.1             | нет         |   512 |     15 | 1 e-3 |          1 |\n",
    "| tiny\\_vit   | TinyViT (patch=16, 4 слоя) | расширенные         | 0.1             | нет         |   256 |     20 | 5 e-4 |          2 |\n",
    "\n",
    "Аугментации:\n",
    "- базовые – RandomResizedCrop + RandomHorizontalFlip\n",
    "- расширенные – полный train_tfms с RandAugment, RandomRotation и др."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_model(name: str) -> dict:\n",
    "    cfg = HP[name]\n",
    "\n",
    "    global train_tfms\n",
    "    if cfg[\"aug\"]:\n",
    "        train_ds.dataset.transform = train_tfms\n",
    "    else:\n",
    "        train_ds.dataset.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.RandomResizedCrop(IMG_SIZE),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(MEAN, STD),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    train_dl, val_dl = make_loaders(\n",
    "        batch=cfg[\"batch\"],\n",
    "    )\n",
    "\n",
    "    if name.startswith(\"res18\"):\n",
    "        model = models.resnet18(\n",
    "            weights=models.ResNet18_Weights.IMAGENET1K_V1,\n",
    "        )\n",
    "        model.fc = nn.Linear(\n",
    "            model.fc.in_features,\n",
    "            num_cls,\n",
    "        )\n",
    "    elif name.startswith(\"vit\"):\n",
    "        model = models.vit_b_16(\n",
    "            weights=models.ViT_B_16_Weights.IMAGENET1K_V1,\n",
    "        )\n",
    "        model.heads.head = nn.Linear(\n",
    "            model.heads.head.in_features,\n",
    "            num_cls,\n",
    "        )\n",
    "        if cfg[\"ckpt\"]:\n",
    "            model.encoder.gradient_checkpointing = True\n",
    "    elif name == \"cnn\":\n",
    "        model = SimpleCNN()\n",
    "    elif name == \"tiny_vit\":\n",
    "        model = TinyViT()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {name}\")\n",
    "\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    # Блок 3: Подготовка к обучению\n",
    "    criterion = nn.CrossEntropyLoss(\n",
    "        label_smoothing=0.1 if cfg[\"aug\"] else 0.0,\n",
    "    )\n",
    "    optimizer = optim.AdamW(\n",
    "        params=model.parameters(),\n",
    "        lr=cfg[\"lr\"],\n",
    "        weight_decay=1e-4,\n",
    "    )\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer=optimizer,\n",
    "        max_lr=cfg[\"lr\"],\n",
    "        epochs=cfg[\"epochs\"],\n",
    "        steps_per_epoch=len(train_dl) // cfg[\"acc_steps\"],\n",
    "    )\n",
    "\n",
    "    # Блок 4: Цикл обучения\n",
    "    print(\n",
    "        f\"\\n─── ▶️  Training {name} \"\n",
    "        \"───────────────────────────\"\n",
    "    )\n",
    "    for epoch in range(1, cfg[\"epochs\"] + 1):\n",
    "        epoch_step(\n",
    "            model=model,\n",
    "            loader=train_dl,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            acc_steps=cfg[\"acc_steps\"],\n",
    "        )\n",
    "        scheduler.step()\n",
    "        _, val_acc = epoch_step(\n",
    "            model=model,\n",
    "            loader=val_dl,\n",
    "            criterion=criterion,\n",
    "        )\n",
    "        print(\n",
    "            f\"Epoch {epoch:02d}/\"\n",
    "            f\"{cfg['epochs']}: val {val_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "    acc, f1, kappa = evaluate_metrics(\n",
    "        model=model,\n",
    "        loader=val_dl,\n",
    "    )\n",
    "    print(\n",
    "        f\"{name} → \"\n",
    "        f\"Acc {acc:.4f} | \"\n",
    "        f\"F1w {f1:.4f} | \"\n",
    "        f\"κ {kappa:.4f}\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Weighted F1\": f1,\n",
    "        \"Cohen κ\": kappa,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кажется началось восстание машин"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "─── ▶️  Training res18_base ───────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/6: val 0.9907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02/6: val 0.9922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03/6: val 0.9914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04/6: val 0.9916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05/6: val 0.9929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06/6: val 0.9932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res18_base → Acc 0.9932 | F1w 0.9932 | κ 0.9897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
      "100%|██████████| 330M/330M [00:04<00:00, 81.6MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "─── ▶️  Training vit_base ───────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/6: val 0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02/6: val 0.9922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03/6: val 0.9916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04/6: val 0.9927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05/6: val 0.9933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06/6: val 0.9927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vit_base → Acc 0.9925 | F1w 0.9925 | κ 0.9888\n",
      "\n",
      "─── ▶️  Training res18_aug ───────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/10: val 0.9880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02/10: val 0.9895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03/10: val 0.9907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04/10: val 0.9913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05/10: val 0.9913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06/10: val 0.9913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07/10: val 0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08/10: val 0.9923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09/10: val 0.9924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: val 0.9919\n",
      "res18_aug → Acc 0.9913 | F1w 0.9913 | κ 0.9870\n",
      "\n",
      "─── ▶️  Training vit_aug ───────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/10: val 0.9908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02/10: val 0.9924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03/10: val 0.9919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04/10: val 0.9917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05/10: val 0.9919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06/10: val 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07/10: val 0.9922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08/10: val 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09/10: val 0.9921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: val 0.9922\n",
      "vit_aug → Acc 0.9918 | F1w 0.9918 | κ 0.9877\n",
      "\n",
      "─── ▶️  Training cnn ───────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/15: val 0.9700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02/15: val 0.9764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03/15: val 0.9817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04/15: val 0.9828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05/15: val 0.9850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06/15: val 0.9839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07/15: val 0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08/15: val 0.9841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09/15: val 0.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15: val 0.9847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15: val 0.9847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15: val 0.9849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15: val 0.9853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15: val 0.9868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15: val 0.9856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn → Acc 0.9853 | F1w 0.9853 | κ 0.9779\n",
      "\n",
      "─── ▶️  Training tiny_vit ───────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/20: val 0.9708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02/20: val 0.9771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03/20: val 0.9784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04/20: val 0.9796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05/20: val 0.9807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06/20: val 0.9799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07/20: val 0.9806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08/20: val 0.9815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09/20: val 0.9813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: val 0.9818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: val 0.9808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: val 0.9813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: val 0.9821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: val 0.9816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: val 0.9820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: val 0.9825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: val 0.9799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: val 0.9829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: val 0.9823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: val 0.9815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiny_vit → Acc 0.9824 | F1w 0.9824 | κ 0.9735\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for m in [\"res18_base\", \"vit_base\",\n",
    "          \"res18_aug\",  \"vit_aug\",\n",
    "          \"cnn\", \"tiny_vit\"]:\n",
    "    results.append(fit_model(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты захвата машинами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Итоговые результаты =====\n",
      "     Model  Accuracy  Weighted F1  Cohen κ\n",
      "res18_base  0.993156     0.993156 0.989734\n",
      "  vit_base  0.992512     0.992511 0.988767\n",
      " res18_aug  0.991345     0.991345 0.987018\n",
      "   vit_aug  0.991775     0.991775 0.987662\n",
      "       cnn  0.985269     0.985265 0.977903\n",
      "  tiny_vit  0.982353     0.982350 0.973529\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "print(\"\\n===== Итоговые результаты =====\")\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
